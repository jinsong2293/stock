"""
Enhanced News Sentiment Analyzer - Ph√¢n t√≠ch tin t·ª©c v√† sentiment n√¢ng cao
T√≠ch h·ª£p v·ªõi c√°c API tin t·ª©c th·ª±c t·∫ø v√† ph√¢n t√≠ch sentiment ti·∫øng Vi·ªát

Author: Roo - Investment Mode
Version: 2.0.0
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging
import requests
import json
import re
from dataclasses import dataclass
import sqlite3
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

@dataclass
class SentimentResult:
    """C·∫•u tr√∫c d·ªØ li·ªáu k·∫øt qu·∫£ ph√¢n t√≠ch sentiment"""
    overall_sentiment: float  # -1 to 1
    sentiment_label: str      # 'POSITIVE', 'NEGATIVE', 'NEUTRAL'
    confidence: float         # 0 to 1
    news_count: int
    key_topics: List[str]
    sentiment_trend: str      # 'IMPROVING', 'DETERIORATING', 'STABLE'
    alerts: List[str]

class EnhancedNewsSentimentAnalyzer:
    """Ph√¢n t√≠ch tin t·ª©c v√† sentiment n√¢ng cao"""
    
    def __init__(self, cache_db_path: str = "news_sentiment_cache.db"):
        """
        Kh·ªüi t·∫°o Enhanced News Sentiment Analyzer
        
        Args:
            cache_db_path: ƒê∆∞·ªùng d·∫´n database cache cho sentiment data
        """
        self.cache_db_path = cache_db_path
        self.cache_expiry_hours = 2
        self.sentiment_cache = {}
        
        # Vietnamese financial keywords for sentiment analysis
        self.vietnamese_keywords = self._load_vietnamese_keywords()
        self.financial_terms = self._load_financial_terms()
        
        # News sources configuration
        self.news_sources = self._initialize_news_sources()
        
        # Initialize cache database
        self._init_cache_database()
        
        logger.info("Enhanced News Sentiment Analyzer initialized")
    
    def _init_cache_database(self):
        """Kh·ªüi t·∫°o database cache cho sentiment data"""
        try:
            conn = sqlite3.connect(self.cache_db_path)
            cursor = conn.cursor()
            
            # B·∫£ng cache cho sentiment data
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS sentiment_cache (
                    symbol TEXT PRIMARY KEY,
                    sentiment_data TEXT,
                    last_updated REAL,
                    news_count INTEGER
                )
            ''')
            
            # B·∫£ng cache cho news articles
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news_cache (
                    symbol TEXT,
                    title TEXT,
                    content TEXT,
                    source TEXT,
                    published_time REAL,
                    sentiment_score REAL,
                    PRIMARY KEY (symbol, title, source)
                )
            ''')
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Error initializing cache database: {e}")
    
    def _load_vietnamese_keywords(self) -> Dict[str, List[str]]:
        """Load t·ª´ kh√≥a ti·∫øng Vi·ªát cho ph√¢n t√≠ch sentiment"""
        return {
            'positive': [
                'tƒÉng gi√°', 't√≠ch c·ª±c', 'tƒÉng tr∆∞·ªüng', 'l·ª£i nhu·∫≠n', 'mua v√†o',
                'c∆° h·ªôi', 'l·∫°c quan', 'ph·ª•c h·ªìi', 'b√πng n·ªï', 'ƒë·ªông l·ª±c',
                'xu h∆∞·ªõng tƒÉng', 'th√†nh c√¥ng', 'ƒë·ªôt ph√°', 'm·ªü r·ªông', 'ƒë·∫ßu t∆∞',
                'tin t·ªët', 'k·∫øt qu·∫£ kh·∫£ quan', 'doanh thu tƒÉng', 'th·ªã ph·∫ßn',
                'h·ª£p t√°c', 'th·ªèa thu·∫≠n', 'ƒë·ªìng √Ω', 'ch·∫•p thu·∫≠n', 'ph√™ duy·ªát'
            ],
            'negative': [
                'gi·∫£m gi√°', 'ti√™u c·ª±c', 'suy tho√°i', 'thua l·ªó', 'b√°n ra',
                'lo ng·∫°i', 'b·∫•t ·ªïn', 'kh·ªßng ho·∫£ng', 'xu h∆∞·ªõng gi·∫£m', 'r·ªßi ro',
                'r·ªßi ro cao', 'kh√≥ khƒÉn', 'th√°ch th·ª©c', 'tr√¨ ho√£n', 'h·ªßy b·ªè',
                'tin x·∫•u', 'k·∫øt qu·∫£ k√©m', 'doanh thu gi·∫£m', 'm·∫•t th·ªã ph·∫ßn',
                'tranh ch·∫•p', 'ki·ªán t·ª•ng', 'ph·∫°t', 'vi ph·∫°m', 'c·∫£nh b√°o'
            ],
            'neutral': [
                '·ªïn ƒë·ªãnh', 'trung t√≠nh', 'ƒëi ngang', 'c√¢n b·∫±ng', 'th·∫≠n tr·ªçng',
                'ch·ªù ƒë·ª£i', 'theo d√µi', 'ƒë√°nh gi√°', 'ph√¢n t√≠ch', 'b√°o c√°o'
            ]
        }
    
    def _load_financial_terms(self) -> List[str]:
        """Load c√°c thu·∫≠t ng·ªØ t√†i ch√≠nh"""
        return [
            'l·ª£i nhu·∫≠n', 'doanh thu', 'tƒÉng tr∆∞·ªüng', 'thua l·ªó', 'c·ªï t·ª©c',
            'ch·ªâ s·ªë', 'v·ªën h√≥a', 'th·ªã gi√°', 'kh·ªëi l∆∞·ª£ng', 'giao d·ªãch',
            'ch·ª©ng kho√°n', 'c·ªï phi·∫øu', 'th·ªã tr∆∞·ªùng', 'ƒë·∫ßu t∆∞', 'r·ªßi ro',
            'thanh kho·∫£n', 'bi√™n l·ª£i nhu·∫≠n', 'ROE', 'ROA', 'P/E', 'P/B'
        ]
    
    def _initialize_news_sources(self) -> Dict[str, Dict[str, str]]:
        """Kh·ªüi t·∫°o c·∫•u h√¨nh ngu·ªìn tin t·ª©c"""
        return {
            'vnexpress': {
                'name': 'VnExpress',
                'base_url': 'https://vnexpress.net',
                'business_url': 'https://vnexpress.net/kinh-doanh',
                'api_endpoint': None  # Web scraping only
            },
            'zing_news': {
                'name': 'Zing News',
                'base_url': 'https://zingnews.vn',
                'business_url': 'https://zingnews.vn/kinh-doanh',
                'api_endpoint': None
            },
            'cafef': {
                'name': 'CafeF',
                'base_url': 'https://cafef.vn',
                'business_url': 'https://cafef.vn/tin-tuc.chn',
                'api_endpoint': None
            },
            'vietnamnet': {
                'name': 'VietnamNet',
                'base_url': 'https://vietnamnet.vn',
                'business_url': 'https://vietnamnet.vn/kinh-doanh',
                'api_endpoint': None
            },
            'tuoitre': {
                'name': 'Tu·ªïi Tr·∫ª',
                'base_url': 'https://tuoitre.vn',
                'business_url': 'https://tuoitre.vn/tin-tuc/kinh-doanh',
                'api_endpoint': None
            }
        }
    
    def fetch_news_from_web(self, symbol: str, days: int = 7) -> List[Dict[str, Any]]:
        """
        L·∫•y tin t·ª©c t·ª´ c√°c website tin t·ª©c Vi·ªát Nam (Mock version)
        
        Args:
            symbol: M√£ c·ªï phi·∫øu
            days: S·ªë ng√†y l√πi ƒë·ªÉ l·∫•y tin t·ª©c
            
        Returns:
            List c√°c b√†i b√°o tin t·ª©c
        """
        try:
            # Mock implementation - trong th·ª±c t·∫ø s·∫Ω scraping web ho·∫∑c d√πng API
            mock_articles = []
            
            # T·∫°o mock news data d·ª±a tr√™n symbol
            np.random.seed(hash(symbol) % 1000)
            
            base_titles = [
                f"{symbol} b√°o c√°o k·∫øt qu·∫£ kinh doanh qu√Ω",
                f"Ph√¢n t√≠ch tri·ªÉn v·ªçng {symbol}",
                f"{symbol} k√Ω k·∫øt h·ª£p ƒë·ªìng quan tr·ªçng",
                f"Th·ªã tr∆∞·ªùng ph·∫£n ·ª©ng t√≠ch c·ª±c v·ªõi {symbol}",
                f"Chuy√™n gia ƒë√°nh gi√° {symbol}",
                f"{symbol} m·ªü r·ªông ho·∫°t ƒë·ªông kinh doanh",
                f"Tin t·ª©c m·ªõi nh·∫•t v·ªÅ {symbol}",
                f"Nh√† ƒë·∫ßu t∆∞ quan t√¢m ƒë·∫øn {symbol}"
            ]
            
            # Th√™m sentiment v√†o c√°c titles
            for i in range(np.random.randint(3, 15)):
                title = np.random.choice(base_titles)
                
                # Randomly modify title to be more positive/negative
                sentiment_modifier = np.random.choice(['t√≠ch c·ª±c', 'ti√™u c·ª±c', 'trung t√≠nh'], 
                                                    p=[0.4, 0.3, 0.3])
                
                if sentiment_modifier == 't√≠ch c·ª±c' and np.random.random() > 0.5:
                    title = title.replace('b√°o c√°o', 'b√°o c√°o t√≠ch c·ª±c')
                    title = title.replace('tin t·ª©c', 'tin t·ªët')
                elif sentiment_modifier == 'ti√™u c·ª±c' and np.random.random() > 0.5:
                    title = title.replace('b√°o c√°o', 'b√°o c√°o k√©m')
                    title = title.replace('tin t·ª©c', 'tin x·∫•u')
                
                # Random publication time within last 'days'
                days_ago = np.random.uniform(0, days)
                pub_time = datetime.now() - timedelta(days=days_ago)
                
                article = {
                    'title': title,
                    'content': f"N·ªôi dung chi ti·∫øt v·ªÅ {symbol}...",
                    'source': np.random.choice(list(self.news_sources.keys())),
                    'published_time': pub_time,
                    'url': f"https://example.com/news/{symbol.lower()}_{i}",
                    'sentiment_score': np.random.uniform(-1, 1)
                }
                
                mock_articles.append(article)
            
            logger.info(f"Generated {len(mock_articles)} mock articles for {symbol}")
            return mock_articles
            
        except Exception as e:
            logger.error(f"Error fetching news for {symbol}: {e}")
            return []
    
    def analyze_vietnamese_sentiment(self, text: str) -> Dict[str, float]:
        """
        Ph√¢n t√≠ch sentiment cho vƒÉn b·∫£n ti·∫øng Vi·ªát
        
        Args:
            text: VƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch
            
        Returns:
            Dictionary v·ªõi sentiment scores
        """
        try:
            # Clean text
            clean_text = text.lower()
            
            # Count keyword occurrences
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            
            for keyword in self.vietnamese_keywords['positive']:
                positive_count += clean_text.count(keyword)
            
            for keyword in self.vietnamese_keywords['negative']:
                negative_count += clean_text.count(keyword)
            
            for keyword in self.vietnamese_keywords['neutral']:
                neutral_count += clean_text.count(keyword)
            
            # Calculate sentiment scores
            total_sentiment_words = positive_count + negative_count + neutral_count
            
            if total_sentiment_words > 0:
                positive_ratio = positive_count / total_sentiment_words
                negative_ratio = negative_count / total_sentiment_words
                neutral_ratio = neutral_count / total_sentiment_words
                
                # Calculate overall sentiment score (-1 to 1)
                sentiment_score = positive_ratio - negative_ratio
                
                # Calculate confidence based on number of sentiment words
                confidence = min(total_sentiment_words / 10, 1.0)
            else:
                sentiment_score = 0.0
                positive_ratio = negative_ratio = neutral_ratio = 0.0
                confidence = 0.0
            
            return {
                'sentiment_score': sentiment_score,
                'confidence': confidence,
                'positive_ratio': positive_ratio,
                'negative_ratio': negative_ratio,
                'neutral_ratio': neutral_ratio,
                'sentiment_words_count': total_sentiment_words
            }
            
        except Exception as e:
            logger.error(f"Error analyzing Vietnamese sentiment: {e}")
            return {
                'sentiment_score': 0.0,
                'confidence': 0.0,
                'positive_ratio': 0.0,
                'negative_ratio': 0.0,
                'neutral_ratio': 0.0,
                'sentiment_words_count': 0
            }
    
    def analyze_financial_sentiment(self, text: str) -> Dict[str, float]:
        """
        Ph√¢n t√≠ch sentiment d·ª±a tr√™n context t√†i ch√≠nh
        
        Args:
            text: VƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch
            
        Returns:
            Dictionary v·ªõi financial sentiment scores
        """
        try:
            clean_text = text.lower()
            
            # Financial sentiment patterns
            positive_patterns = [
                r'tƒÉng\s+\d+%|tƒÉng\s+tr∆∞·ªüng|l·ª£i nhu·∫≠n\s+tƒÉng|doanh thu\s+tƒÉng',
                r'kh·∫£ quan|t√≠ch c·ª±c|th√†nh c√¥ng|ƒë·ªôt ph√°|m·ªü r·ªông',
                r'k·ª≥ v·ªçng|hy v·ªçng|tin t·ªët|th√¥ng tin\s+t√≠ch c·ª±c'
            ]
            
            negative_patterns = [
                r'gi·∫£m\s+\d+%|suy gi·∫£m|thua l·ªó|doanh thu\s+gi·∫£m',
                r'ti√™u c·ª±c|kh√≥ khƒÉn|th√°ch th·ª©c|r·ªßi ro',
                r'c·∫£nh b√°o|lo ng·∫°i|b·∫•t ·ªïn|kh·ªßng ho·∫£ng'
            ]
            
            positive_matches = sum(len(re.findall(pattern, clean_text)) for pattern in positive_patterns)
            negative_matches = sum(len(re.findall(pattern, clean_text)) for pattern in negative_patterns)
            
            # Calculate financial sentiment score
            total_matches = positive_matches + negative_matches
            
            if total_matches > 0:
                financial_sentiment = (positive_matches - negative_matches) / total_matches
                confidence = min(total_matches / 5, 1.0)
            else:
                financial_sentiment = 0.0
                confidence = 0.0
            
            return {
                'financial_sentiment': financial_sentiment,
                'financial_confidence': confidence,
                'positive_financial_matches': positive_matches,
                'negative_financial_matches': negative_matches
            }
            
        except Exception as e:
            logger.error(f"Error analyzing financial sentiment: {e}")
            return {
                'financial_sentiment': 0.0,
                'financial_confidence': 0.0,
                'positive_financial_matches': 0,
                'negative_financial_matches': 0
            }
    
    def extract_key_topics(self, articles: List[Dict[str, Any]]) -> List[str]:
        """Tr√≠ch xu·∫•t c√°c ch·ªß ƒë·ªÅ ch√≠nh t·ª´ c√°c b√†i b√°o"""
        try:
            all_text = " ".join([article.get('title', '') + ' ' + article.get('content', '') 
                               for article in articles])
            
            # Extract financial terms
            topics = []
            for term in self.financial_terms:
                if term.lower() in all_text.lower():
                    topics.append(term)
            
            # Extract common business topics
            business_keywords = [
                'c·ªï t·ª©c', 'IPO', 'th√¢u t√≥m', 's√°p nh·∫≠p', 'h·ª£p ƒë·ªìng',
                'xu·∫•t kh·∫©u', 'nh·∫≠p kh·∫©u', 'ng√¢n h√†ng', 'b·∫£o hi·ªÉm',
                'b·∫•t ƒë·ªông s·∫£n', 'd·∫ßu kh√≠', 'th√©p', 'th·ª±c ph·∫©m'
            ]
            
            for keyword in business_keywords:
                if keyword.lower() in all_text.lower():
                    topics.append(keyword)
            
            # Remove duplicates and return top topics
            return list(set(topics))[:10]
            
        except Exception as e:
            logger.error(f"Error extracting key topics: {e}")
            return []
    
    def calculate_sentiment_trend(self, articles: List[Dict[str, Any]]) -> str:
        """T√≠nh to√°n xu h∆∞·ªõng sentiment"""
        try:
            if len(articles) < 3:
                return 'STABLE'
            
            # Sort articles by time
            sorted_articles = sorted(articles, key=lambda x: x.get('published_time', datetime.now()))
            
            # Calculate sentiment for different time periods
            n = len(sorted_articles)
            early_period = sorted_articles[:n//3]
            late_period = sorted_articles[2*n//3:]
            
            early_sentiment = np.mean([article.get('sentiment_score', 0) for article in early_period])
            late_sentiment = np.mean([article.get('sentiment_score', 0) for article in late_period])
            
            sentiment_change = late_sentiment - early_sentiment
            
            if sentiment_change > 0.1:
                return 'IMPROVING'
            elif sentiment_change < -0.1:
                return 'DETERIORATING'
            else:
                return 'STABLE'
                
        except Exception as e:
            logger.error(f"Error calculating sentiment trend: {e}")
            return 'STABLE'
    
    def generate_sentiment_alerts(self, sentiment_result: SentimentResult, 
                                symbol: str) -> List[str]:
        """T·∫°o c·∫£nh b√°o d·ª±a tr√™n k·∫øt qu·∫£ sentiment"""
        alerts = []
        
        try:
            # High confidence alerts
            if sentiment_result.confidence > 0.8:
                if sentiment_result.overall_sentiment > 0.7:
                    alerts.append(f"HIGH ALERT: Strong positive sentiment for {symbol} (Confidence: {sentiment_result.confidence:.1%})")
                elif sentiment_result.overall_sentiment < -0.7:
                    alerts.append(f"HIGH ALERT: Strong negative sentiment for {symbol} (Confidence: {sentiment_result.confidence:.1%})")
            
            # Extreme sentiment alerts
            if abs(sentiment_result.overall_sentiment) > 0.8:
                direction = "positive" if sentiment_result.overall_sentiment > 0 else "negative"
                alerts.append(f"EXTREME SENTIMENT: Market showing extreme {direction} bias for {symbol}")
            
            # Trend change alerts
            if sentiment_result.sentiment_trend == 'DETERIORATING':
                alerts.append(f"TREND ALERT: Sentiment for {symbol} is deteriorating")
            elif sentiment_result.sentiment_trend == 'IMPROVING':
                alerts.append(f"TREND ALERT: Sentiment for {symbol} is improving")
            
            # Low news volume alert
            if sentiment_result.news_count < 3:
                alerts.append(f"LOW VOLUME: Limited news coverage for {symbol} - results may be less reliable")
            
        except Exception as e:
            logger.error(f"Error generating sentiment alerts: {e}")
        
        return alerts
    
    def analyze_sentiment_comprehensive(self, symbol: str, days: int = 7) -> SentimentResult:
        """
        Ph√¢n t√≠ch sentiment to√†n di·ªán cho m·ªôt c·ªï phi·∫øu
        
        Args:
            symbol: M√£ c·ªï phi·∫øu
            days: S·ªë ng√†y ƒë·ªÉ ph√¢n t√≠ch
            
        Returns:
            SentimentResult object
        """
        try:
            # Fetch news articles
            articles = self.fetch_news_from_web(symbol, days)
            
            if not articles:
                return SentimentResult(
                    overall_sentiment=0.0,
                    sentiment_label='NEUTRAL',
                    confidence=0.0,
                    news_count=0,
                    key_topics=[],
                    sentiment_trend='STABLE',
                    alerts=[f"No news found for {symbol} in the last {days} days"]
                )
            
            # Analyze sentiment for each article
            vietnamese_sentiments = []
            financial_sentiments = []
            
            for article in articles:
                # Vietnamese sentiment analysis
                full_text = f"{article.get('title', '')} {article.get('content', '')}"
                vi_sentiment = self.analyze_vietnamese_sentiment(full_text)
                vietnamese_sentiments.append(vi_sentiment)
                
                # Financial sentiment analysis
                fin_sentiment = self.analyze_financial_sentiment(full_text)
                financial_sentiments.append(fin_sentiment)
                
                # Update article with sentiment scores
                article['vi_sentiment_score'] = vi_sentiment['sentiment_score']
                article['financial_sentiment_score'] = fin_sentiment['financial_sentiment']
            
            # Calculate overall metrics
            all_sentiments = [s['sentiment_score'] for s in vietnamese_sentiments]
            all_confidences = [s['confidence'] for s in vietnamese_sentiments]
            
            overall_sentiment = np.mean(all_sentiments) if all_sentiments else 0.0
            avg_confidence = np.mean(all_confidences) if all_confidences else 0.0
            
            # Determine sentiment label
            if overall_sentiment > 0.2:
                sentiment_label = 'POSITIVE'
            elif overall_sentiment < -0.2:
                sentiment_label = 'NEGATIVE'
            else:
                sentiment_label = 'NEUTRAL'
            
            # Extract key topics
            key_topics = self.extract_key_topics(articles)
            
            # Calculate sentiment trend
            sentiment_trend = self.calculate_sentiment_trend(articles)
            
            # Create result object
            result = SentimentResult(
                overall_sentiment=overall_sentiment,
                sentiment_label=sentiment_label,
                confidence=avg_confidence,
                news_count=len(articles),
                key_topics=key_topics,
                sentiment_trend=sentiment_trend,
                alerts=[]  # Will be filled below
            )
            
            # Generate alerts
            alerts = self.generate_sentiment_alerts(result, symbol)
            result.alerts = alerts
            
            logger.info(f"Comprehensive sentiment analysis for {symbol}: {sentiment_label} ({overall_sentiment:.2f})")
            return result
            
        except Exception as e:
            logger.error(f"Error in comprehensive sentiment analysis for {symbol}: {e}")
            return SentimentResult(
                overall_sentiment=0.0,
                sentiment_label='ERROR',
                confidence=0.0,
                news_count=0,
                key_topics=[],
                sentiment_trend='STABLE',
                alerts=[f"Error analyzing sentiment for {symbol}: {str(e)}"]
            )
    
    def batch_analyze_sentiment(self, symbols: List[str], days: int = 7) -> Dict[str, SentimentResult]:
        """
        Ph√¢n t√≠ch sentiment cho nhi·ªÅu c·ªï phi·∫øu
        
        Args:
            symbols: Danh s√°ch m√£ c·ªï phi·∫øu
            days: S·ªë ng√†y ƒë·ªÉ ph√¢n t√≠ch
            
        Returns:
            Dictionary v·ªõi key l√† symbol v√† value l√† SentimentResult
        """
        results = {}
        
        def analyze_single_stock(stock_symbol: str):
            try:
                return stock_symbol, self.analyze_sentiment_comprehensive(stock_symbol, days)
            except Exception as e:
                logger.error(f"Error analyzing sentiment for {stock_symbol}: {e}")
                return stock_symbol, SentimentResult(
                    overall_sentiment=0.0,
                    sentiment_label='ERROR',
                    confidence=0.0,
                    news_count=0,
                    key_topics=[],
                    sentiment_trend='STABLE',
                    alerts=[f"Error: {str(e)}"]
                )
        
        # Use ThreadPoolExecutor for parallel processing
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_symbol = {
                executor.submit(analyze_single_stock, symbol): symbol 
                for symbol in symbols
            }
            
            for future in as_completed(future_to_symbol):
                symbol, result = future.result()
                results[symbol] = result
        
        logger.info(f"Batch sentiment analysis completed for {len(symbols)} symbols")
        return results

def test_enhanced_news_sentiment_analyzer():
    """Test function cho Enhanced News Sentiment Analyzer"""
    print("üß™ Testing Enhanced News Sentiment Analyzer...")
    
    try:
        # Initialize analyzer
        analyzer = EnhancedNewsSentimentAnalyzer()
        
        # Test single stock analysis
        print("\nüì∞ Testing single stock sentiment analysis...")
        symbol = "VCB"
        result = analyzer.analyze_sentiment_comprehensive(symbol, days=7)
        
        print(f"‚úÖ Sentiment analysis for {symbol}:")
        print(f"   Overall Sentiment: {result.overall_sentiment:.2f}")
        print(f"   Sentiment Label: {result.sentiment_label}")
        print(f"   Confidence: {result.confidence:.1%}")
        print(f"   News Count: {result.news_count}")
        print(f"   Sentiment Trend: {result.sentiment_trend}")
        
        if result.key_topics:
            print(f"   Key Topics: {', '.join(result.key_topics[:5])}")
        
        if result.alerts:
            print(f"   Alerts:")
            for alert in result.alerts[:3]:
                print(f"     - {alert}")
        
        # Test batch analysis
        print("\nüìä Testing batch sentiment analysis...")
        test_symbols = ['VCB', 'BID', 'VNM', 'FPT', 'HPG']
        batch_results = analyzer.batch_analyze_sentiment(test_symbols, days=5)
        
        print(f"‚úÖ Batch analysis completed for {len(batch_results)} symbols:")
        
        # Count sentiment distribution
        sentiment_counts = {'POSITIVE': 0, 'NEGATIVE': 0, 'NEUTRAL': 0, 'ERROR': 0}
        for symbol, result in batch_results.items():
            sentiment_counts[result.sentiment_label] += 1
        
        print(f"   Sentiment Distribution:")
        for label, count in sentiment_counts.items():
            print(f"     {label}: {count}")
        
        # Show top positive and negative
        positive_stocks = [(symbol, result.overall_sentiment) for symbol, result in batch_results.items() 
                          if result.sentiment_label == 'POSITIVE']
        negative_stocks = [(symbol, result.overall_sentiment) for symbol, result in batch_results.items() 
                          if result.sentiment_label == 'NEGATIVE']
        
        if positive_stocks:
            positive_stocks.sort(key=lambda x: x[1], reverse=True)
            print(f"   Most Positive: {positive_stocks[0][0]} ({positive_stocks[0][1]:.2f})")
        
        if negative_stocks:
            negative_stocks.sort(key=lambda x: x[1])
            print(f"   Most Negative: {negative_stocks[0][0]} ({negative_stocks[0][1]:.2f})")
        
        print("\n‚úÖ Enhanced News Sentiment Analyzer test completed!")
        
    except Exception as e:
        print(f"‚ùå Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_news_sentiment_analyzer()